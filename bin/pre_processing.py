#!/usr/bin/env python3

import argparse
from argparse import ArgumentParser as AP
import os
import pandas as pd
import sys

import glob
from myslim.datasets.convert import _convert_dataset

from os.path import abspath
import time
from pathlib import Path

def get_args():
    # Script description
    description = """Convert tiles to TFrecords"""
    # Add parser
    parser = AP(description=description,
                formatter_class=argparse.RawDescriptionHelpFormatter)

    # Sections
    parser.add_argument("--slides_folder", help="Set slides folder", default = "")
    parser.add_argument("--output_dir", help="Set output folder", default = "")
    parser.add_argument("--file_info_train",
                        help="Set to path to 'file_info_train.txt' generated by create_file_info_train.py")
    parser.add_argument(
        "--N_shards", help="Number of shards", default=320, type=int)
    parser.add_argument("--version", action="version", version="0.1.0")
    arg = parser.parse_args()
    arg.output_dir = abspath(arg.output_dir)

    if ((arg.output_dir != "") & (not os.path.isdir(arg.output_dir))):
        # Create an empty folder for TF records if folder doesn't exist
        arg.output_dir = Path(arg.output_dir,"process_train")
        os.mkdir(arg.output_dir)
    return arg

def execute_preprocessing(file_info_train, output_dir, N_shards=320):
    """
    Execute several pre-processing steps necessary for extracting the histopathological features
    1. Create tiles from slides
    2. Construct file necessary for the deep learning architecture
    3. Convert images of tiles to TF records

    Args:
        slides_folder (str): path pointing to folder with all whole slide images (.svs files)
        output_dir (str): path pointing to folder for storing all created files by script
        clinical_file_path (str): path pointing to formatted clinical file (either generated or manually formatted)
        N_shards (int): default: 320

    Returns:
        {output_dir}/tiles/{tile files}
        {output_dir}/file_info_train.txt file specifying data structure of the tiles required for inception architecture (to read the TF records)
        {output_dir}/process_train/{TFrecord file} files that store the data as a series of binary sequencies

    """
    # Convert tiles from jpg to TF record1
    file_info = pd.read_csv(file_info_train, sep="\t")
    training_filenames = list(file_info["tile_path"].values)
    training_classids = [int(id) for id in list(file_info["class_id"].values)]
    tps = [int(id) for id in list(file_info["percent_tumor_cells"].values)]
    Qs = list(file_info["jpeg_quality"].values)

    _convert_dataset(
        split_name="train",
        filenames=training_filenames,
        tps=tps,
        Qs=Qs,
        classids=training_classids,
        output_dir=output_dir,
        NUM_SHARDS=N_shards,
    )

def main(args):
    execute_preprocessing(
        output_dir=args.output_dir,
        file_info_train=args.file_info_train,
        N_shards=args.N_shards
    )

    out_files = glob.glob1(Path(args.output_dir), "*.tfrecord")
    print(len(out_files))

    assert len(out_files) == args.N_shards

    print("Finished converting dataset")
    print(
        f"The converted data is stored in the directory: {args.output_dir}")


if __name__ == "__main__":
    args = get_args()
    st = time.time()
    main(args)
    rt = time.time() - st
    print(f"Script finished in {rt // 60:.0f}m {rt % 60:.0f}s")
